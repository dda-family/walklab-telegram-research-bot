import os
import re
import feedparser
import requests
from datetime import datetime, timedelta, timezone
from dateutil import parser as dateparser

# =============================
# ê¸°ë³¸ ì„¤ì •
# =============================
MAX_ARTICLES = 10
TIME_WINDOW_HOURS = 48

KST = timezone(timedelta(hours=9))
now_kst = datetime.now(KST)
cutoff_kst = now_kst - timedelta(hours=TIME_WINDOW_HOURS)

TELEGRAM_BOT_TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN")
TELEGRAM_CHAT_ID = os.environ.get("TELEGRAM_CHAT_ID")

if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID:
    raise RuntimeError("Missing TELEGRAM_BOT_TOKEN or TELEGRAM_CHAT_ID in environment variables.")

# =============================
# RSS ëª©ë¡ (ê²½ìŸì‚¬ + íŠ¸ë Œë“œ + ì‹¤ë£¨ì—£/ìì„¸)
# =============================
RSS_FEEDS = [

    # ===== ê²½ìŸì‚¬ =====
    # AIT Studio / MediStep
    'https://news.google.com/rss/search?q=("AIT+Studio"+OR+AITìŠ¤íŠœë””ì˜¤+OR+ì—ì´íŠ¸ìŠ¤íŠœë””ì˜¤)+(MediStep+OR+ë©”ë””ìŠ¤í…)+(gait+OR+ë³´í–‰)&hl=ko&gl=KR&ceid=KR:ko',

    # Angel Robotics
    'https://news.google.com/rss/search?q=("Angel+Robotics"+OR+ì—”ì ¤ë¡œë³´í‹±ìŠ¤)+("Angel+Legs"+OR+M20)+(gait+OR+rehabilitation)&hl=ko&gl=KR&ceid=KR:ko',

    # WIRobotics
    'https://news.google.com/rss/search?q=("WIRobotics"+OR+ìœ„ë¡œë³´í‹±ìŠ¤)+(gait+OR+ì›¨ì–´ëŸ¬ë¸”)&hl=ko&gl=KR&ceid=KR:ko',

    # Spina Systems / PediSol
    'https://news.google.com/rss/search?q=(PediSol+OR+í˜ë””ì†”+OR+"Spina+Systems")+("smart+insole"+OR+ì¡±ì €ì••)&hl=ko&gl=KR&ceid=KR:ko',

    # Ochy
    'https://news.google.com/rss/search?q=(Ochy)+(gait)&hl=en-US&gl=US&ceid=US:en',

    # ExaMD / LocoStep
    'https://news.google.com/rss/search?q=("LocoStep"+OR+"ExaMD")+(gait)&hl=en-US&gl=US&ceid=US:en',

    # OneStep
    'https://news.google.com/rss/search?q=("OneStep")+(gait+OR+rehabilitation)&hl=en-US&gl=US&ceid=US:en',

    # ===== ê¸°ì¡´ íŠ¸ë Œë“œ 4ì¶• =====

    # ì˜ìƒ ê¸°ë°˜ ì„ìƒ/ê²€ì¦
    'https://news.google.com/rss/search?q=("smartphone+video+gait"+OR+"video+gait+analysis")+(clinical+OR+validation)&hl=en-US&gl=US&ceid=US:en',

    # ë³´í—˜ / ë¦¬ìŠ¤í¬
    'https://news.google.com/rss/search?q=("gait+digital+biomarker"+OR+"mobility+data")+(insurance+OR+underwriting)&hl=en-US&gl=US&ceid=US:en',

    # ê³ ë ¹ì ë‚™ìƒ
    'https://news.google.com/rss/search?q=("fall+prevention"+OR+"fall+risk")+(elderly+OR+seniors)&hl=en-US&gl=US&ceid=US:en',

    # ì§ˆí™˜ ì˜ˆì¸¡
    'https://news.google.com/rss/search?q=("gait+diabetes"+OR+"gait+Parkinson")+(AI+OR+model)&hl=en-US&gl=US&ceid=US:en',

    # ===== ì¶”ê°€: ìì„¸(ì‹¤ë£¨ì—£) 1ì¶• =====

    # ì˜ë¬¸ ì‹¤ë£¨ì—£/ìì„¸
    'https://news.google.com/rss/search?q=("silhouette+analysis"+OR+"silhouette-based"+OR+"silhouette+score"+OR+clustering)+("posture"+OR+"pose+estimation"+OR+"motion+analysis"+OR+biomechanics)+(gait+OR+rehabilitation+OR+healthcare+OR+clinical)&hl=en-US&gl=US&ceid=US:en',

    # êµ­ë¬¸ ì‹¤ë£¨ì—£/ìì„¸
    'https://news.google.com/rss/search?q=(ì‹¤ë£¨ì—£+OR+ìì„¸+OR+í¬ì¦ˆì¶”ì •+OR+êµ°ì§‘ë¶„ì„)+(ë³´í–‰+OR+ì¬í™œ+OR+í—¬ìŠ¤ì¼€ì–´+OR+ì˜ë£Œ)+-íŒ¨ì…˜+-ì˜ë¥˜+-ì‚¬ì§„&hl=ko&gl=KR&ceid=KR:ko',
]

# =============================
# íƒœê·¸ ë¶„ë¥˜
# =============================
COMPANY_KEYWORDS = [
    "AIT Studio", "AITìŠ¤íŠœë””ì˜¤", "ì—ì´íŠ¸ìŠ¤íŠœë””ì˜¤", "MediStep", "ë©”ë””ìŠ¤í…",
    "Angel Robotics", "ì—”ì ¤ë¡œë³´í‹±ìŠ¤", "Angel Legs", "M20",
    "WIRobotics", "ìœ„ë¡œë³´í‹±ìŠ¤",
    "Spina Systems", "ìŠ¤í”¼ë‚˜ì‹œìŠ¤í…œì¦ˆ", "PediSol", "í˜ë””ì†”",
    "Ochy", "LocoStep", "ExaMD", "OneStep"
]

TAG_RULES = {
    "ğŸ’°íˆ¬ì": ["funding", "series", "investment", "raises"],
    "ğŸ¤ì œíœ´": ["partnership", "collaboration", "mou"],
    "ğŸ¥ì„ìƒ": ["clinical", "trial", "fda", "validation", "hospital"],
    "ğŸ›ê³µê³µ": ["government", "city", "public"],
    "ğŸ›¡ë³´í—˜": ["insurance", "underwriting", "payer"],
    "ğŸ“±ì˜ìƒê¸°ë°˜": ["smartphone", "video", "camera", "markerless"],
    "ğŸ§ì‹¤ë£¨ì—£": [
        "silhouette analysis", "silhouette-based", "silhouette score",
        "clustering", "cluster analysis",
        "posture", "pose estimation", "biomechanics",
        "ì‹¤ë£¨ì—£", "ìì„¸", "í¬ì¦ˆì¶”ì •", "êµ°ì§‘ë¶„ì„"
    ]
}

def send_telegram(message: str):
    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
    payload = {
        "chat_id": TELEGRAM_CHAT_ID,
        "text": message,
        "parse_mode": "HTML",
        "disable_web_page_preview": True
    }
    r = requests.post(url, data=payload, timeout=20)
    r.raise_for_status()

def normalize_title(title):
    return re.sub(r"[^0-9a-zA-Zê°€-í£]+", "", title).lower()

def parse_published_kst(entry):
    if hasattr(entry, "published"):
        try:
            dt = dateparser.parse(entry.published)
            if dt.tzinfo is None:
                dt = dt.replace(tzinfo=timezone.utc)
            return dt.astimezone(KST)
        except:
            return None
    return None

def classify_tags(title, summary):
    text = (title + " " + summary).lower()
    tags = []

    for kw in COMPANY_KEYWORDS:
        if kw.lower() in text:
            tags.append("ğŸ¢ê²½ìŸì‚¬")
            break

    for tag, kws in TAG_RULES.items():
        for k in kws:
            if k.lower() in text:
                tags.append(tag)
                break

    return tags

def calc_priority(tags):
    score = 0
    if "ğŸ¢ê²½ìŸì‚¬" in tags:
        score += 100
    if "ğŸ’°íˆ¬ì" in tags:
        score += 30
    if "ğŸ¥ì„ìƒ" in tags:
        score += 30
    if "ğŸ¤ì œíœ´" in tags:
        score += 20
    if "ğŸ›¡ë³´í—˜" in tags:
        score += 15
    if "ğŸ›ê³µê³µ" in tags:
        score += 15
    if "ğŸ§ì‹¤ë£¨ì—£" in tags:
        score += 10
    if "ğŸ“±ì˜ìƒê¸°ë°˜" in tags:
        score += 8
    return score

def main():
    articles = []
    seen_links = set()
    seen_titles = set()

    for feed_url in RSS_FEEDS:
        feed = feedparser.parse(feed_url)

        for entry in getattr(feed, "entries", []):
            published_kst = parse_published_kst(entry)
            if not published_kst:
                continue
            if published_kst < cutoff_kst:
                continue

            link = getattr(entry, "link", "").strip()
            title = getattr(entry, "title", "").strip()
            summary = getattr(entry, "summary", "")

            if not link or not title:
                continue

            norm_title = normalize_title(title)

            if link in seen_links or norm_title in seen_titles:
                continue

            seen_links.add(link)
            seen_titles.add(norm_title)

            tags = classify_tags(title, summary)
            priority = calc_priority(tags)

            articles.append({
                "title": title,
                "link": link,
                "tags": tags,
                "priority": priority,
                "published_kst": published_kst
            })

    articles.sort(key=lambda x: (x["priority"], x["published_kst"]), reverse=True)
    top = articles[:MAX_ARTICLES]

    if not top:
        send_telegram("ğŸ“¡ ì˜¤ëŠ˜ ì‹ ê·œ ê¸°ì‚¬ ì—†ìŒ (ìµœê·¼ 48ì‹œê°„ ê¸°ì¤€)")
        return

    msg = "ğŸ“¡ <b>ì›Œí¬ë© ë¦¬ì„œì¹˜ ë¸Œë¦¬í•‘</b>\n(ìµœê·¼ 48ì‹œê°„ / ìƒìœ„ 10ê±´)\n\n"
    for i, a in enumerate(top, 1):
        tag_text = " ".join(a["tags"]) if a["tags"] else ""
        msg += f"{i}. {tag_text}\n<b>{a['title']}</b>\n{a['link']}\n\n"

    send_telegram(msg)

if __name__ == "__main__":
    main()
